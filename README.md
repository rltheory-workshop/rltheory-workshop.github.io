# The second RL theory workshop (co-located with COLT 2024)

We would like to invite you to the second\* RL theory workshop, taking place 27-29 June 2024 at the University of Alberta (Co-located with COLT; COLT commences on the 30th of June). Schedule:
- Evening of June 27th: dinner and drinks (starting, say, 19:30)
- June 28th: Full day of talks and discussions, some fun activity in the evening
- June 29th: First half dedicated to talks, second half to recreation and
winding-down before COLT

The workshop is free to attend, but we cannot provide funding or accomodation.

To get a VISA invitation letter, please use [this](https://forms.gle/RVGUXsjQbAFsNdvz6) form on the COLT website, noting in the "additional input" box that whether you will attend COLT, or just the workshop. We will generate the COLT invitation letter for you and if you need any modification to it, please let us know after receiving the letter.


We look forward to seeing you there,<br/>
*David Janz (david.janz93 AT gmail.com), Alex Ayoub & Csaba Szepesv√°ri*

\*Recordings from last year's workshop are available [here](https://www.youtube.com/playlist?list=PLOtn0gtfk-RnuiDoj7oDP9LZ7pdOj5vtO).

## Organisational details

The workshop will take place at or nearby the Computing Science Centre of the University of Alberta; this is the same location as COLT. Regarding accommodation, two reasonable choices are:
- Guest rooms at the university (Lister dorms), [website](https://www.ualberta.ca/conference-services/accommodation/guest-rooms.html)
- Campus tower hotel, [website](https://www.campustower.com/)
  
The first is on campus, the second a three minute walk away.

## Tentative talks list
### Core RL theory
- *Optimistic Q-learning for weakly communicating MDPs,* **Shipra Agrawal**
- *Truncated Variance Reduced Value Iteration,* **Ishani Aniruddha Karmarkar**
- *A Computationally Efficient Algorithm for Infinite-Horizon Average Reward Reinforcement Learning with Linear MDPs,* **Ki Hong**
- *Offline Reinforcement Learning: Role of State Aggregation and Trajectory Data,* **Zeyu Jia**, [paper link](https://arxiv.org/abs/2403.17091)
- *Statistical and Algorithmic Reductions for Reinforcement Learning From Rich Observations,* **Philip Amortila**
- *Scalable Online Exploration via Coverability,* **Philip Amortila**, [paper link](https://arxiv.org/abs/2403.06571)
- *On the Instance-dependent Sample Complexity of Tabular RL*, **Kevin Jamieson**
- *Uncertainty-Aware Reward-Free Exploration with General Function Approximation,* **Zhou, Dongruo**
- *Towards Principled, Practical Policy Gradient for Bandits and Tabular MDPs,* **Sharan Vaswani**

### Bandits
- *The Dissimilarity Dimension: Sharper Bounds for Optimistic Algorithms,* **Aldo Pacchiano**, [paper link](https://arxiv.org/abs/2306.06184)

### Game theory
- *Reinforcement Learning in Mean Field Games: the pitfalls and promises,* **Niao He**
- *When are Offline Multi-Agent Games Solvable?,* **Simon Du**

### Other fun topics
- *Reinforcement Learning from Human Feedback with Active Queries,* **Jiafan He**
- *Efficient exploration in deep RL via utility theory,* **Brendan O'Donoghue**
- *Bisimulation Metrics are Optimal Transport Distances,
and Can be Computed Efficiently,* **Gergely Neu**
- *Robust Online Learning in the Presence of Outliers,* **Tim van Erven**, [paper link](https://arxiv.org/abs/2107.01881)

